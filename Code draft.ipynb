{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b071e5",
   "metadata": {},
   "source": [
    "# Deep Reinforcment Learning Coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39da1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env is a  ?X? matrix    -  no restriction but cqn mqke it bigger later for difficulty "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a3f15",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16680bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6c6c5",
   "metadata": {},
   "source": [
    "# Define States and Actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = A1 A2 A3 A4 A5 B1 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = up down left right "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989e982",
   "metadata": {},
   "source": [
    "# Create R table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3408b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.empty((5,5))\n",
    "R = np.array(R)\n",
    "R[:] = np.nan\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ff92e",
   "metadata": {},
   "source": [
    "# Create the Q table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros(R.shape)\n",
    "\n",
    "print('Q matrix: \\n\\n{}'.format(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1741f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this approach was the easy one with S A. Can we use Gym for project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b31b27",
   "metadata": {},
   "source": [
    "# Basic, up to 50 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296084c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 10 marks: Define an environment and the problem to be solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f383f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ZooEnvironment:\n",
    "    def __init__(self):\n",
    "        self.grid_size = (5, 5)\n",
    "        self.zoo_layout = [\n",
    "            ['CLEANING', 'LION', None, None, 'CLEANING'],\n",
    "            [None, 'ELEPHANT', 'SHOP', None, None],\n",
    "            [None, None, 'SHOP', 'PINGUIN', None],\n",
    "            ['SHOP', None, None, None, 'SHOP'],\n",
    "            ['GIRAFFE', None, None, None, 'CLEANING']\n",
    "        ]\n",
    "        self.agent_pos = None  # Agent position will be set during reset\n",
    "        self.num_actions = 4  # Four possible actions: up, down, left, right\n",
    "\n",
    "    def reset(self):\n",
    "        # Randomly select a starting position for the agent\n",
    "        self.agent_pos = (random.randint(0, self.grid_size[0] - 1), random.randint(0, self.grid_size[1] - 1))\n",
    "        return self.agent_pos\n",
    "\n",
    "    def step(self, action):\n",
    "        # Define action mapping: 0 - up, 1 - down, 2 - left, 3 - right\n",
    "        action_map = {0: (-1, 0), 1: (1, 0), 2: (0, -1), 3: (0, 1)}\n",
    "        \n",
    "        # Get the next position based on the action\n",
    "        next_row = self.agent_pos[0] + action_map[action][0]\n",
    "        next_col = self.agent_pos[1] + action_map[action][1]\n",
    "        \n",
    "        # Check if the next position is within bounds\n",
    "        if 0 <= next_row < self.grid_size[0] and 0 <= next_col < self.grid_size[1]:\n",
    "            next_cell = self.zoo_layout[next_row][next_col]\n",
    "            if next_cell is not None and next_cell != 'CLEANING' and next_cell != 'SHOP':\n",
    "                # Valid move, update agent position\n",
    "                self.agent_pos = (next_row, next_col)\n",
    "                # 2. 05 marks: Define a state transition function and the reward function\n",
    "                if next_cell == 'LION' or next_cell == 'ELEPHANT' or next_cell == 'PINGUIN' or next_cell == 'GIRAFFE':\n",
    "                    reward = 10  # Reward for visiting an animal enclosure\n",
    "                else:\n",
    "                    reward = 0  # No reward for visiting other cells\n",
    "                done = False\n",
    "            else:\n",
    "                # Hit obstacle, stay in the same position, negative reward\n",
    "                reward = -1\n",
    "                done = False\n",
    "        else:\n",
    "            # Out of bounds, stay in the same position, negative reward\n",
    "            reward = -1\n",
    "            done = False\n",
    "\n",
    "        return self.agent_pos, reward, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then implement Qlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3457327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 3. 05 marks: Set up the Q-learning parameters (gamma,alpha) and policy\n",
    "    \n",
    "class QLearningAgent:\n",
    "    def __init__(self, num_actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\n",
    "        self.num_actions = num_actions\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = np.zeros((5, 5, num_actions))  # Q-table initialized with zeros\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            # Explore: select a random action\n",
    "            return np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            # Exploit: select the action with the highest Q-value for the current state\n",
    "            return np.argmax(self.q_table[state[0], state[1]])\n",
    "    \n",
    "    def update_q_values(self, state, action, reward, next_state):\n",
    "        # Q-learning update rule\n",
    "        best_next_action = np.argmax(self.q_table[next_state[0], next_state[1]])\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state[0], next_state[1], best_next_action]\n",
    "        td_error = td_target - self.q_table[state[0], state[1], action]\n",
    "        self.q_table[state[0], state[1], action] += self.learning_rate * td_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 10 marks: Run the Q-learning algorithm and represent its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48adbefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d6b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 10 marks: Repeat the experiment with different parameter values, and policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61e56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b666338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 10 marks: Analyze the results quantitatively and qualitatively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd25ba",
   "metadata": {},
   "source": [
    "# Advanced, up to 50 marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600aff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
